"""
PTZ Face Blur Service
Notebook Cell 1: Y√ºzlerin Blur'lanmasƒ±
S3'ten snapshot'larƒ± alƒ±r, y√ºzleri blur'lar ve tekrar S3'e y√ºkler.
"""
import os
import cv2
import torch
from pathlib import Path
from datetime import datetime
from facenet_pytorch import MTCNN
import boto3
from botocore.exceptions import ClientError
from botocore.config import Config
from dotenv import load_dotenv
# urllib3 SSL uyarƒ±larƒ±nƒ± bastƒ±r (self-signed certificate i√ßin)
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# .env dosyasƒ±nƒ± y√ºkle
load_dotenv()

# AWS checksum hesaplama ve doƒürulama i√ßin environment variable'larƒ± ayarla
# Bu, bazƒ± S3 uyumlu sistemlerde (Cohesity gibi) Content-Length sorunlarƒ±nƒ± √ß√∂zebilir
os.environ.setdefault("AWS_REQUEST_CHECKSUM_CALCULATION", "when_required")
os.environ.setdefault("AWS_RESPONSE_CHECKSUM_VALIDATION", "when_required")

# === Klas√∂rler ===
SNAPSHOTS_ROOT = Path("snapshots")  # camera_XXX/YYYY-MM-DD/HH/*.jpg

# === S3 Object Storage Ayarlarƒ± ===
S3_ENDPOINT_URL = os.getenv("S3_ENDPOINT_URL", "https://161cohesity.carrefoursa.com:3000")
S3_ACCESS_KEY_ID = os.getenv("S3_ACCESS_KEY_ID", "sWxdTl3ERx7myBE1qpW06_haVvuhATcdsmBbqaWkXYU")
S3_SECRET_ACCESS_KEY = os.getenv("S3_SECRET_ACCESS_KEY", "Ti9Fonk3wYyG5PMx5LaGUmlcVyCuqsE5BLVV5vv8PU0")
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME", "Grocery")

_s3_client = None

def _ensure_s3_client():
    """S3 client'ƒ± ba≈ülat"""
    global _s3_client
    if not S3_ACCESS_KEY_ID or not S3_SECRET_ACCESS_KEY:
        return None
    if _s3_client is None:
        _s3_client = boto3.client(
            "s3",
            endpoint_url=S3_ENDPOINT_URL,
            aws_access_key_id=S3_ACCESS_KEY_ID,
            aws_secret_access_key=S3_SECRET_ACCESS_KEY,
            verify=False,  # self-signed i√ßin
            config=Config(
                signature_version="s3v4",
                s3={"addressing_style": "path"},  # √ñNEMLƒ∞: path style
            ),
        )
    return _s3_client

def _upload_file(local_path: Path, s3_key: str, content_type: str = "image/jpeg"):
    """Dosyayƒ± S3'e y√ºkle (varsa √ºzerine yazar)."""
    s3 = _ensure_s3_client()
    if not s3:
        return None
    try:
        if not local_path.exists():
            print(f"‚ö†Ô∏è  Lokal dosya bulunamadƒ±: {local_path}")
            return None
        
        # Dosyayƒ± okuyup bytes olarak al
        with open(local_path, "rb") as f:
            data = f.read()
        
        # put_object kullan (ContentLength otomatik hesaplanƒ±r)
        s3.put_object(
            Bucket=S3_BUCKET_NAME,
            Key=s3_key,
            Body=data,
            ContentType=content_type
        )
        return s3_key
    except Exception as e:
        print(f"‚ö†Ô∏è  S3 upload hatasƒ± ({s3_key}): {e}")
        return None

def _download_file(s3_key: str, local_path: Path) -> bool:
    """S3'ten dosyayƒ± indir"""
    s3 = _ensure_s3_client()
    if not s3:
        return False
    try:
        local_path.parent.mkdir(parents=True, exist_ok=True)
        s3.download_file(S3_BUCKET_NAME, s3_key, str(local_path))
        return True
    except ClientError as e:
        print(f"‚ö†Ô∏è  S3 indirme hatasƒ± ({s3_key}): {e}")
        return False

def _list_blobs_in_path(prefix: str) -> list:
    """S3'te belirli bir prefix altƒ±ndaki t√ºm object'leri listele"""
    s3 = _ensure_s3_client()
    if not s3:
        return []
    try:
        blobs = []
        paginator = s3.get_paginator('list_objects_v2')
        pages = paginator.paginate(Bucket=S3_BUCKET_NAME, Prefix=prefix)
        for page in pages:
            if 'Contents' in page:
                for obj in page['Contents']:
                    blobs.append(obj['Key'])
        return sorted(blobs)
    except ClientError as e:
        print(f"‚ö†Ô∏è  S3 listeleme hatasƒ± ({prefix}): {e}")
        return []

device = 'cuda' if torch.cuda.is_available() else 'cpu'
mtcnn = MTCNN(keep_all=True, device=device)

def _to_snapshot_blob_path(local_path: Path) -> str:
    """SNAPSHOTS_ROOT'e g√∂re baƒüƒ±l yolu blob yoluna √ßevirir: snapshots/<...>"""
    rel = local_path.relative_to(SNAPSHOTS_ROOT)
    return f"snapshots/{rel.as_posix()}"

def blur_faces(img_path: Path):
    """Y√ºzleri bulanƒ±kla≈ütƒ±r, yerinde kaydet ve S3 Object Storage'a aynƒ± yapƒ±yla y√ºkle."""
    img = cv2.imread(str(img_path))
    if img is None:
        print(f"‚ö†Ô∏è  G√∂rsel okunamadƒ±: {img_path}")
        return None

    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    boxes, _ = mtcnn.detect(rgb)

    if boxes is not None:
        for box in boxes:
            x1, y1, x2, y2 = [int(coord) for coord in box]
            face = img[y1:y2, x1:x2]
            if face.size == 0:
                continue
            blurred = cv2.GaussianBlur(face, (51, 51), 30)
            img[y1:y2, x1:x2] = blurred

    cv2.imwrite(str(img_path), img)

    # S3'e y√ºkle
    s3_key = _to_snapshot_blob_path(img_path)
    _upload_file(img_path, s3_key, content_type="image/jpeg")
    print(f"‚úîÔ∏è  Blur+Upload: {img_path.name} -> {s3_key}")
    return s3_key

def process_all_cameras_snapshots():
    """S3'ten t√ºm kameralar i√ßin son saat klas√∂r√ºndeki g√∂r√ºnt√ºleri indir, blur'la ve S3'e y√ºkle."""
    import tempfile
    import shutil
    
    # Ge√ßici klas√∂r olu≈ütur
    temp_dir = Path(tempfile.mkdtemp(prefix="face_blur_"))
    
    try:
        # S3'ten t√ºm kameralarƒ± bul
        prefix = "snapshots/camera_"
        all_blobs = _list_blobs_in_path(prefix)
        
        if not all_blobs:
            print("[!] S3'te snapshot bulunamadƒ±")
            return
        
        # Kamera -> tarih -> saat yapƒ±sƒ±nƒ± olu≈ütur
        camera_data = {}
        for blob_path in all_blobs:
            parts = blob_path.split("/")
            if len(parts) >= 4 and parts[1].startswith("camera_"):
                camera_id = parts[1]
                date_name = parts[2]
                hour_name = parts[3]
                filename = parts[4] if len(parts) > 4 else None
                
                if filename and filename.lower().endswith(('.jpg', '.jpeg')):
                    key = (camera_id, date_name, hour_name)
                    if key not in camera_data:
                        camera_data[key] = []
                    camera_data[key].append(blob_path)
        
        if not camera_data:
            print("[!] ƒ∞≈ülenecek snapshot bulunamadƒ±")
            return
        
        # Her kamera i√ßin en son tarih/saat klas√∂r√ºn√º i≈üle
        processed_cameras = set()
        for (camera_id, date_name, hour_name), s3_keys in camera_data.items():
            if camera_id in processed_cameras:
                continue
            
            # En son tarih/saat i√ßin sadece bir kez i≈üle
            print(f"\nüì∑ Kamera: {camera_id} | üìÅ {date_name}/{hour_name}")
            
            # S3'ten snapshot'larƒ± indir
            for s3_key in s3_keys:
                filename = s3_key.split('/')[-1]
                local_path = temp_dir / camera_id / date_name / hour_name / filename
                local_path.parent.mkdir(parents=True, exist_ok=True)
                
                if _download_file(s3_key, local_path):
                    try:
                        blur_faces(local_path)
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Hata ({filename}): {e}")
            
            processed_cameras.add(camera_id)
    
    finally:
        # Ge√ßici klas√∂r√º temizle
        if temp_dir.exists():
            shutil.rmtree(temp_dir, ignore_errors=True)
            print(f"[i] Ge√ßici klas√∂r temizlendi: {temp_dir}")

if __name__ == "__main__":
    print("="*60)
    print("PTZ Face Blur Service - Ba≈ülatƒ±lƒ±yor...")
    print("="*60)
    process_all_cameras_snapshots()
    print("="*60)
    print("PTZ Face Blur Service - Tamamlandƒ±")
    print("="*60)

