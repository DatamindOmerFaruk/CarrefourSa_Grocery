"""
Azure Storage'dan gÃ¶rselleri alÄ±p API'lara gÃ¶ndererek PostgreSQL'e yazan batch processor
"""
import os
import requests
import psycopg2
from psycopg2.extras import RealDictCursor
import json
from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions
from datetime import datetime, timedelta
import logging
from typing import List, Dict, Any, Optional
import time
from urllib.parse import quote
from dotenv import load_dotenv

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# Logging ayarlarÄ±
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('batch_processor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BatchProcessor:
    def __init__(self):
        """KonfigÃ¼rasyonlarÄ± yÃ¼kle"""
        self.load_config()
        self.setup_connections()
        
    def load_config(self):
        """Ã‡evre deÄŸiÅŸkenlerinden konfigÃ¼rasyonlarÄ± yÃ¼kle"""
        # Azure Storage
        self.azure_connection_string = os.getenv('AZURE_STORAGE_CONNECTION_STRING')
        self.container_name = os.getenv('AZURE_CONTAINER_NAME', 'snapshot')
        self.sas_token = os.getenv('AZURE_SAS_TOKEN')
        
        # Connection string'den account name'i Ã§Ä±kar
        conn_parts = dict(x.split('=', 1) for x in self.azure_connection_string.split(';') if '=' in x)
        self.account_name = conn_parts.get('AccountName')
        
        # PostgreSQL
        self.pg_host = os.getenv('POSTGRES_HOST', '45.84.18.76')
        self.pg_port = os.getenv('POSTGRES_PORT', '5432')
        self.pg_database = os.getenv('POSTGRES_DB', 'grocerryadmin')
        self.pg_user = os.getenv('POSTGRES_USER', 'grocerryadmin')
        self.pg_password = os.getenv('POSTGRES_PASSWORD', 'a08Iyr95vLHTYY')
        
        # API Endpoints
        self.api_base_url = os.getenv('API_BASE_URL', 'http://localhost:8000')
        self.test_mode = os.getenv('TEST_MODE', 'false').lower() == 'true'
        
        # Batch ayarlarÄ±
        self.batch_size = int(os.getenv('BATCH_SIZE', '10'))
        self.retry_count = int(os.getenv('RETRY_COUNT', '3'))
        self.delay_between_requests = float(os.getenv('REQUEST_DELAY', '1.0'))
        
        if not all([self.azure_connection_string, self.pg_database, self.pg_user, self.pg_password]):
            raise ValueError("Gerekli Ã§evre deÄŸiÅŸkenleri eksik!")
            
    def setup_connections(self):
        """Azure ve PostgreSQL baÄŸlantÄ±larÄ±nÄ± kur"""
        try:
            # Azure Blob Service Client
            self.blob_service_client = BlobServiceClient.from_connection_string(
                self.azure_connection_string
            )
            
            # PostgreSQL baÄŸlantÄ±sÄ±
            self.pg_connection = psycopg2.connect(
                host=self.pg_host,
                port=self.pg_port,
                database=self.pg_database,
                user=self.pg_user,
                password=self.pg_password
            )
            self.pg_connection.autocommit = True
            
            logger.info("Azure Storage ve PostgreSQL baÄŸlantÄ±larÄ± baÅŸarÄ±lÄ±")
            
        except Exception as e:
            logger.error(f"BaÄŸlantÄ± hatasÄ±: {str(e)}")
            raise
            
    def get_all_images(self) -> List[Dict[str, str]]:
        """Azure Storage'dan tÃ¼m gÃ¶rselleri listele"""
        try:
            container_client = self.blob_service_client.get_container_client(self.container_name)
            blobs = []
            
            for blob in container_client.list_blobs():
                # Sadece resim dosyalarÄ±nÄ± al
                if blob.name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):

                    # Normal URL ve SAS token'lÄ± URL oluÅŸtur
                    blob_url = f"{container_client.url}/{quote(blob.name)}"
                    sas_url = f"https://{self.account_name}.blob.core.windows.net/{self.container_name}/{quote(blob.name)}?{self.sas_token}"
                    
                    blobs.append({
                        'name': blob.name,
                        'url': blob_url,
                        'sas_url': sas_url,
                        'folder': '/'.join(blob.name.split('/')[:-1]) if '/' in blob.name else '',
                        'size': blob.size,
                        'last_modified': blob.last_modified
                    })
                    
            logger.info(f"Toplam {len(blobs)} gÃ¶rsel dosyasÄ± bulundu")
            return blobs
            
        except Exception as e:
            logger.error(f"Azure Storage'dan dosya listesi alÄ±namadÄ±: {str(e)}")
            raise
            
    def download_image(self, blob_name: str) -> bytes:
        """GÃ¶rseli Azure Storage'dan indir"""
        try:
            blob_client = self.blob_service_client.get_blob_client(
                container=self.container_name, 
                blob=blob_name
            )
            return blob_client.download_blob().readall()
            
        except Exception as e:
            logger.error(f"GÃ¶rsel indirilemedi ({blob_name}): {str(e)}")
            raise
            
    def call_api(self, endpoint: str, image_bytes: bytes, additional_data: Dict = None) -> Dict:
        """API endpoint'ine gÃ¶rsel gÃ¶nder"""
        url = f"{self.api_base_url}/{endpoint}"
        
        files = {'file': ('image.jpg', image_bytes, 'image/jpeg')}
        data = additional_data or {}
        
        for attempt in range(self.retry_count):
            try:
                logger.info(f"API Ã§aÄŸrÄ±sÄ±: {url}")
                response = requests.post(url, files=files, data=data, timeout=120)
                logger.info(f"Response status: {response.status_code}")
                if response.status_code != 200:
                    logger.error(f"Response content: {response.text}")
                response.raise_for_status()
                return response.json()
                
            except Exception as e:
                logger.warning(f"API Ã§aÄŸrÄ±sÄ± baÅŸarÄ±sÄ±z (deneme {attempt + 1}/{self.retry_count}): {str(e)}")
                if attempt == self.retry_count - 1:
                    raise
    def call_api_with_url(self, endpoint: str, image_url: str, additional_data: Dict = None) -> Dict:
        """API endpoint'ine SAS URL gÃ¶nder"""
        url = f"{self.api_base_url}/{endpoint}"
        
        data = {'image_url': image_url}
        if additional_data:
            data.update(additional_data)
        
        for attempt in range(self.retry_count):
            try:
                logger.info(f"API Ã§aÄŸrÄ±sÄ±: {url} with URL: {image_url[:100]}...")
                response = requests.post(url, data=data, timeout=120)
                logger.info(f"Response status: {response.status_code}")
                if response.status_code != 200:
                    logger.error(f"Response content: {response.text}")
                response.raise_for_status()
                return response.json()
                
            except Exception as e:
                logger.warning(f"API Ã§aÄŸrÄ±sÄ± baÅŸarÄ±sÄ±z (deneme {attempt + 1}/{self.retry_count}): {str(e)}")
                if attempt == self.retry_count - 1:
                    raise
                time.sleep(2 ** attempt)  # Exponential backoff
                
    def process_content_api(self, sas_url: str, source_url: str) -> Dict:
        """Content API'yi SAS URL ile Ã§aÄŸÄ±r"""
        try:
            result = self.call_api_with_url('analyze/content', sas_url)
            
            if not result.get('success'):
                raise Exception(f"API hatasÄ±: {result.get('error', 'Bilinmeyen hata')}")
                
            return {
                'success': True,
                'data': result['data'],
                'timestamp': result['timestamp']
            }
            
        except Exception as e:
            logger.error(f"Content API hatasÄ± ({source_url}): {str(e)}")
            return {'success': False, 'error': str(e)}
            
    def process_stock_api(self, sas_url: str, source_url: str) -> Dict:
        """Stock API'yi SAS URL ile Ã§aÄŸÄ±r"""
        try:
            result = self.call_api_with_url('analyze/stock', sas_url)
            
            if not result.get('success'):
                raise Exception(f"API hatasÄ±: {result.get('error', 'Bilinmeyen hata')}")
                
            return {
                'success': True,
                'data': result['data'],
                'timestamp': result['timestamp']
            }
            
        except Exception as e:
            logger.error(f"Stock API hatasÄ± ({source_url}): {str(e)}")
            return {'success': False, 'error': str(e)}
            
    def process_evaluation_api(self, sas_url: str, source_url: str, content_data: Dict = None) -> Dict:
        """Evaluation API'yi SAS URL ile Ã§aÄŸÄ±r"""
        try:
            additional_data = {}
            if content_data and content_data.get('success'):
                additional_data['content_data'] = json.dumps(content_data['data'])
                
            result = self.call_api_with_url('analyze/evaluation', sas_url, additional_data)
            
            if not result.get('success'):
                raise Exception(f"API hatasÄ±: {result.get('error', 'Bilinmeyen hata')}")
                
            return {
                'success': True,
                'data': result['data'],
                'timestamp': result['timestamp']
            }
            
        except Exception as e:
            logger.error(f"Evaluation API hatasÄ± ({source_url}): {str(e)}")
            return {'success': False, 'error': str(e)}
            
    def save_content_results(self, source_url: str, content_data: Dict):
        """Content sonuÃ§larÄ±nÄ± analyze_row tablosuna kaydet"""
        if not content_data.get('success'):
            return
            
        try:
            data = content_data['data']
            grid_info = data.get('grid_bilgisi', {})
            tablo_format = data.get('tablo_format', {})
            satirlar = tablo_format.get('satirlar', [])
            
            with self.pg_connection.cursor() as cursor:
                for idx, satir in enumerate(satirlar):
                    cursor.execute("""
                        INSERT INTO analyze_row (
                            source_url, satir_sayisi, sutun_sayisi, toplam_kasa,
                            row_index, konum, ana_urun, yan_urunler, raw
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """, (
                        source_url,
                        grid_info.get('satir_sayisi'),
                        grid_info.get('sutun_sayisi'),
                        grid_info.get('toplam_kasa'),
                        idx,
                        satir.get('konum', ''),
                        satir.get('ana_urun', ''),
                        satir.get('yan_urunler', ''),
                        json.dumps(data, ensure_ascii=False)
                    ))
                    
            logger.info(f"Content sonuÃ§larÄ± kaydedildi: {len(satirlar)} satÄ±r")
            
        except Exception as e:
            logger.error(f"Content kaydetme hatasÄ±: {str(e)}")
            
    def save_stock_results(self, source_url: str, stock_data: Dict):
        """Stock sonuÃ§larÄ±nÄ± analyze_stock_row tablosuna kaydet - BASÄ°T METÄ°N FORMAT"""
        if not stock_data.get('success'):
            return
            
        try:
            data = stock_data['data']
            reyon_durumlari = data.get('reyon_durumlarÄ±', [])
            ozet = data.get('Ã¶zet', {})
            
            # Basit metin Ã¶zeti oluÅŸtur
            dolu_reyonlar = []
            normal_reyonlar = []
            kritik_reyonlar = []
            bos_reyonlar = []
            
            for reyon in reyon_durumlari:
                urun = reyon.get('Ã¼rÃ¼n', '')
                konum = reyon.get('konum', '')
                durum = reyon.get('durum', '')
                
                if durum == 'dolu':
                    dolu_reyonlar.append(f"{urun} ({konum})")
                elif durum == 'normal':
                    normal_reyonlar.append(f"{urun} ({konum})")
                elif durum == 'kritik':
                    kritik_reyonlar.append(f"{urun} ({konum})")
                elif durum == 'boÅŸ':
                    bos_reyonlar.append(f"BoÅŸ kasa ({konum})")
            
            # Basit metin Ã¶zeti
            doluluk_ozeti = []
            if dolu_reyonlar:
                doluluk_ozeti.append(f"DOLU: {', '.join(dolu_reyonlar)}")
            if normal_reyonlar:
                doluluk_ozeti.append(f"NORMAL: {', '.join(normal_reyonlar)}")
            if kritik_reyonlar:
                doluluk_ozeti.append(f"KRÄ°TÄ°K: {', '.join(kritik_reyonlar)}")
            if bos_reyonlar:
                doluluk_ozeti.append(f"BOÅž: {', '.join(bos_reyonlar)}")
            
            doluluk_metni = " | ".join(doluluk_ozeti)
            
            with self.pg_connection.cursor() as cursor:
                # Tek bir satÄ±r olarak kaydet (Ã¶zet)
                cursor.execute("""
                    INSERT INTO analyze_stock_row (
                        source_url, reyon_id, doluluk, durum, aciliyet,
                        kasa_gorunurlugu, doluluk_seviyeleri, raw
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    source_url,
                    f"Toplam {ozet.get('toplam_kasa', len(reyon_durumlari))} kasa",
                    None,  # Doluluk oranÄ± gerek yok
                    f"Dolu:{ozet.get('dolu_kasa', 0)} Normal:{ozet.get('normal_kasa', 0)} Kritik:{ozet.get('kritik_kasa', 0)} BoÅŸ:{ozet.get('boÅŸ_kasa', 0)}",
                    'orta' if ozet.get('kritik_kasa', 0) > 0 or ozet.get('boÅŸ_kasa', 0) > 0 else 'dÃ¼ÅŸÃ¼k',
                    True,
                    doluluk_metni,  # BASÄ°T METÄ°N FORMAT!
                    json.dumps(data, ensure_ascii=False)
                ))
                    
            logger.info(f"Stock sonuÃ§larÄ± kaydedildi: {len(reyon_durumlari)} reyon (BASÄ°T METÄ°N)")
            logger.info(f"Doluluk Ã¶zeti: {doluluk_metni}")
            
        except Exception as e:
            logger.error(f"Stock kaydetme hatasÄ±: {str(e)}")
            
    def save_evaluation_results(self, source_url: str, evaluation_data: Dict):
        """Evaluation sonuÃ§larÄ±nÄ± analyze_evaluation_row tablosuna kaydet"""
        if not evaluation_data.get('success'):
            return
            
        try:
            data = evaluation_data['data']
            degerlendirme = data.get('degerlendirme_sonucu', {})
            hatalar = data.get('tespit_edilen_hatalar', [])
            olumlu_yerlesimler = data.get('olumlu_yerlesimler', [])
            genel_oneriler = data.get('genel_oneriler', [])
            analiz_modu = data.get('analiz_modu', '')
            
            with self.pg_connection.cursor() as cursor:
                if hatalar:
                    # Her hata iÃ§in ayrÄ± satÄ±r
                    for hata in hatalar:
                        cursor.execute("""
                            INSERT INTO analyze_evaluation_row (
                                source_url, genel_skor, toplam_hata, kritik_hata, uyari,
                                analiz_modu, hata_tipi, konum1, urun1, konum2, urun2,
                                problem, oneri, olumlu_yerlesimler, genel_oneriler, raw
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        """, (
                            source_url,
                            degerlendirme.get('genel_skor'),
                            degerlendirme.get('toplam_hata'),
                            degerlendirme.get('kritik_hata'),
                            degerlendirme.get('uyari'),
                            analiz_modu,
                            hata.get('hata_tipi'),
                            hata.get('konum1'),
                            hata.get('urun1'),
                            hata.get('konum2'),
                            hata.get('urun2'),
                            hata.get('problem'),
                            hata.get('oneri'),
                            json.dumps(olumlu_yerlesimler, ensure_ascii=False),
                            json.dumps(genel_oneriler, ensure_ascii=False),
                            json.dumps(data, ensure_ascii=False)
                        ))
                else:
                    # Hata yoksa tek satÄ±r
                    cursor.execute("""
                        INSERT INTO analyze_evaluation_row (
                            source_url, genel_skor, toplam_hata, kritik_hata, uyari,
                            analiz_modu, olumlu_yerlesimler, genel_oneriler, raw
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """, (
                        source_url,
                        degerlendirme.get('genel_skor'),
                        degerlendirme.get('toplam_hata'),
                        degerlendirme.get('kritik_hata'),
                        degerlendirme.get('uyari'),
                        analiz_modu,
                        json.dumps(olumlu_yerlesimler, ensure_ascii=False),
                        json.dumps(genel_oneriler, ensure_ascii=False),
                        json.dumps(data, ensure_ascii=False)
                    ))
                    
            logger.info(f"Evaluation sonuÃ§larÄ± kaydedildi: {len(hatalar) or 1} satÄ±r")
            
        except Exception as e:
            logger.error(f"Evaluation kaydetme hatasÄ±: {str(e)}")
            
    def process_single_image_stock_only(self, blob_info: Dict) -> Dict:
        """Tek gÃ¶rseli iÅŸle - SADECE STOCK ANALÄ°ZÄ°"""
        sas_url = blob_info['sas_url']  # SAS token'lÄ± URL'i source_url olarak kullan
        blob_name = blob_info['name']
        
        logger.info(f"Stock analizi: {blob_name}")
        logger.info(f"SAS URL: {sas_url[:100]}...")
        
        try:
            # Sadece Stock API'sini Ã§aÄŸÄ±r
            stock_result = self.process_stock_api(sas_url, sas_url)
            
            # SonuÃ§larÄ± kaydet (SAS URL'i source_url olarak)
            self.save_stock_results(sas_url, stock_result)
            
            return {
                'success': True,
                'blob_name': blob_name,
                'source_url': sas_url,
                'stock_success': stock_result.get('success', False)
            }
            
        except Exception as e:
            logger.error(f"Stock analizi hatasÄ± ({blob_name}): {str(e)}")
            return {
                'success': False,
                'blob_name': blob_name,
                'source_url': sas_url,
                'error': str(e)
            }

    def process_single_image(self, blob_info: Dict) -> Dict:
        """Tek gÃ¶rseli iÅŸle - SAS URL ile"""
        sas_url = blob_info['sas_url']  # SAS token'lÄ± URL'i source_url olarak kullan
        blob_name = blob_info['name']
        
        logger.info(f"Ä°ÅŸleniyor: {blob_name}")
        logger.info(f"SAS URL source_url olarak kaydedilecek: {sas_url[:100]}...")
        
        try:
            # API'leri sÄ±rayla Ã§aÄŸÄ±r (SAS URL ile)
            content_result = self.process_content_api(sas_url, sas_url)
            time.sleep(self.delay_between_requests)
            
            stock_result = self.process_stock_api(sas_url, sas_url)
            time.sleep(self.delay_between_requests)
            
            evaluation_result = self.process_evaluation_api(
                sas_url, sas_url, content_result
            )
            
            # SonuÃ§larÄ± kaydet (SAS URL'i source_url olarak)
            self.save_content_results(sas_url, content_result)
            self.save_stock_results(sas_url, stock_result)
            self.save_evaluation_results(sas_url, evaluation_result)
            
            return {
                'success': True,
                'blob_name': blob_name,
                'source_url': sas_url,
                'content_success': content_result.get('success', False),
                'stock_success': stock_result.get('success', False),
                'evaluation_success': evaluation_result.get('success', False)
            }
            
        except Exception as e:
            logger.error(f"GÃ¶rsel iÅŸleme hatasÄ± ({blob_name}): {str(e)}")
            return {
                'success': False,
                'blob_name': blob_name,
                'source_url': sas_url,
                'error': str(e)
            }
            
    def run_batch_processing(self):
        """Ana batch iÅŸlem dÃ¶ngÃ¼sÃ¼"""
        logger.info("Batch iÅŸlemi baÅŸlatÄ±lÄ±yor...")
        
        try:
            # TÃ¼m gÃ¶rselleri listele
            all_images = self.get_all_images()
            
            if not all_images:
                logger.warning("Ä°ÅŸlenecek gÃ¶rsel bulunamadÄ±")
                return
                
            # Ä°statistikler
            total_images = len(all_images)
            processed = 0
            successful = 0
            failed = 0
            
            logger.info(f"Toplam {total_images} gÃ¶rsel iÅŸlenecek")
            
            # Batch'ler halinde iÅŸle
            for i in range(0, total_images, self.batch_size):
                batch = all_images[i:i + self.batch_size]
                batch_num = (i // self.batch_size) + 1
                
                logger.info(f"Batch {batch_num} iÅŸleniyor ({len(batch)} gÃ¶rsel)")
                
                for blob_info in batch:
                    result = self.process_single_image(blob_info)
                    processed += 1
                    
                    if result['success']:
                        successful += 1
                        logger.info(f"[OK] {result['blob_name']} baÅŸarÄ±lÄ± ({processed}/{total_images})")
                    else:
                        failed += 1
                        logger.error(f"[FAIL] {result['blob_name']} baÅŸarÄ±sÄ±z ({processed}/{total_images})")
                        
                    # Progress raporu
                    if processed % 10 == 0:
                        progress = (processed / total_images) * 100
                        logger.info(f"Ä°lerleme: {progress:.1f}% ({processed}/{total_images})")
                        
                # Batch arasÄ± bekleme
                if i + self.batch_size < total_images:
                    logger.info(f"Batch tamamlandÄ±, {self.delay_between_requests}s bekleniyor...")
                    time.sleep(self.delay_between_requests)
                    
            # Final rapor
            logger.info("=" * 60)
            logger.info("BATCH Ä°ÅžLEMÄ° TAMAMLANDI")
            logger.info(f"Toplam iÅŸlenen: {processed}")
            logger.info(f"BaÅŸarÄ±lÄ±: {successful}")
            logger.info(f"BaÅŸarÄ±sÄ±z: {failed}")
            logger.info(f"BaÅŸarÄ± oranÄ±: {(successful/processed)*100:.1f}%")
            logger.info("=" * 60)
            
        except Exception as e:
            logger.error(f"Batch iÅŸlemi genel hatasÄ±: {str(e)}")
            raise
            
    def run_stock_only_processing(self):
        """SADECE STOCK ANALÄ°ZÄ° iÃ§in batch iÅŸlem dÃ¶ngÃ¼sÃ¼"""
        logger.info("Stock-Only Batch iÅŸlemi baÅŸlatÄ±lÄ±yor...")
        
        try:
            # TÃ¼m gÃ¶rselleri listele
            all_images = self.get_all_images()
            
            if not all_images:
                logger.warning("Ä°ÅŸlenecek gÃ¶rsel bulunamadÄ±")
                return
                
            # Ä°statistikler
            total_images = len(all_images)
            processed = 0
            successful = 0
            failed = 0
            
            logger.info(f"Toplam {total_images} gÃ¶rsel SADECE STOCK ANALÄ°ZÄ° iÃ§in iÅŸlenecek")
            
            # Batch'ler halinde iÅŸle
            for i in range(0, total_images, self.batch_size):
                batch = all_images[i:i + self.batch_size]
                batch_num = (i // self.batch_size) + 1
                
                logger.info(f"Stock Batch {batch_num} iÅŸleniyor ({len(batch)} gÃ¶rsel)")
                
                for blob_info in batch:
                    result = self.process_single_image_stock_only(blob_info)
                    processed += 1
                    
                    if result['success']:
                        successful += 1
                        logger.info(f"[STOCK OK] {result['blob_name']} baÅŸarÄ±lÄ± ({processed}/{total_images})")
                    else:
                        failed += 1
                        logger.error(f"[STOCK FAIL] {result['blob_name']} baÅŸarÄ±sÄ±z ({processed}/{total_images})")
                        
                    # Progress raporu
                    if processed % 10 == 0:
                        progress = (processed / total_images) * 100
                        logger.info(f"Stock Ä°lerleme: {progress:.1f}% ({processed}/{total_images})")
                        
                    # Request arasÄ± kÄ±sa bekleme
                    time.sleep(1)
                        
                # Batch arasÄ± bekleme
                if i + self.batch_size < total_images:
                    logger.info(f"Stock Batch tamamlandÄ±, {self.delay_between_requests}s bekleniyor...")
                    time.sleep(self.delay_between_requests)
                    
            # Final rapor
            logger.info("=" * 60)
            logger.info("STOCK-ONLY BATCH Ä°ÅžLEMÄ° TAMAMLANDI")
            logger.info(f"Toplam iÅŸlenen: {processed}")
            logger.info(f"BaÅŸarÄ±lÄ±: {successful}")
            logger.info(f"BaÅŸarÄ±sÄ±z: {failed}")
            logger.info(f"BaÅŸarÄ± oranÄ±: {(successful/processed)*100:.1f}%")
            logger.info("=" * 60)
            
        except Exception as e:
            logger.error(f"Stock batch iÅŸlemi genel hatasÄ±: {str(e)}")
            raise
            
    def close_connections(self):
        """BaÄŸlantÄ±larÄ± kapat"""
        try:
            if hasattr(self, 'pg_connection'):
                self.pg_connection.close()
            logger.info("BaÄŸlantÄ±lar kapatÄ±ldÄ±")
        except Exception as e:
            logger.error(f"BaÄŸlantÄ± kapatma hatasÄ±: {str(e)}")


def main():
    """Ana fonksiyon"""
    processor = None
    
    try:
        processor = BatchProcessor()
        
        # KullanÄ±cÄ±dan mode seÃ§imi
        print("\nðŸ” Batch Processor ModlarÄ±:")
        print("1. Tam Analiz (Content + Stock + Evaluation)")
        print("2. Sadece Stock Analizi (HÄ±zlÄ±)")
        
        while True:
            choice = input("\nHangi modu Ã§alÄ±ÅŸtÄ±rmak istiyorsun? (1/2): ").strip()
            if choice == "1":
                logger.info("TAM ANALÄ°Z modu seÃ§ildi")
                processor.run_batch_processing()
                break
            elif choice == "2":
                logger.info("SADECE STOCK ANALÄ°ZÄ° modu seÃ§ildi")
                processor.run_stock_only_processing()
                break
            else:
                print("âŒ GeÃ§ersiz seÃ§im! 1 veya 2 girin.")
        
    except KeyboardInterrupt:
        logger.info("Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan durduruldu")
        
    except Exception as e:
        logger.error(f"Ana iÅŸlem hatasÄ±: {str(e)}")
        raise
        
    finally:
        if processor:
            processor.close_connections()


if __name__ == "__main__":
    main()